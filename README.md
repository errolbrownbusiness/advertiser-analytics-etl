# ğŸ“Š Advertiser Analytics ETL Pipeline
### End-to-End Data Engineering Project (Python, Pandas, Logging, Validation)

This project builds a **production-style ETL pipeline** that processes raw marketplace data (Olist dataset) into **analytics-ready advertiser KPIs**.  
It mirrors real data engineering workflows used in retail media and marketplace analytics.

---

## ğŸš€ Project Summary

This ETL pipeline:

- Loads raw marketplace data (orders, items, customers, products)  
- Cleans, merges, and standardizes datasets  
- Builds an advertiser-level **fact table**  
- Computes daily & monthly KPIs  
- Validates data with **Pandera**  
- Logs every stage using a production-style logger  
- Saves analytics-ready CSV outputs  

The project follows a modular **src/** architecture similar to enterprise DE codebases.

---

## ğŸ§± Tech Stack

- Python 3.11  
- Pandas  
- Pandera  
- PyArrow  
- Logging  
- Pathlib  
- Conda environment  

---

## ğŸ“ Project Structure

```
ms_ad_analytics_project/
â”‚
â”œâ”€â”€ data/                           # Raw input CSVs (ignored by Git)
â”œâ”€â”€ output/                         # Final KPI outputs
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extract.py                  # Extract step
â”‚   â”œâ”€â”€ transform.py                # Clean, merge, build fact table
â”‚   â”œâ”€â”€ validate.py                 # Pandera schemas
â”‚   â”œâ”€â”€ load.py                     # Save outputs
â”‚   â”œâ”€â”€ logger.py                   # Custom logger
â”‚   â”œâ”€â”€ config.py                   # Settings + log level
â”‚   â”œâ”€â”€ pipeline.py                 # Main ETL pipeline
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ advertiser_spend_analytics.ipynb
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ—ï¸ Pipeline Architecture (Mermaid Diagram)

```mermaid
flowchart TD

    A[Raw CSV Files<br/>orders, items, customers] --> B[Extract<br/>extract.py]
    B --> C[Clean & Normalize Data<br/>transform.py]
    C --> D[Build Advertiser Fact Table<br/>transform.py]
    D --> E[Validate with Pandera<br/>validate.py]
    E --> F[Compute KPIs<br/>daily + monthly]
    F --> G[Load Outputs<br/>load.py]
    G --> H[Output Folder<br/>CSV exports]

    %% Styles
    classDef yellow fill:#f8d568,stroke:#b8860b,stroke-width:2px,color:#000;
    classDef blue fill:#8ec5fc,stroke:#4682b4,stroke-width:2px,color:#000;
    classDef green fill:#b5e8c8,stroke:#2e8b57,stroke-width:2px,color:#000;
    classDef purple fill:#f6d7fa,stroke:#8b3a9e,stroke-width:2px,color:#000;
    classDef red fill:#ffe6e6,stroke:#cc0000,stroke-width:2px,color:#000;
    classDef lightblue fill:#e8e8ff,stroke:#6666cc,stroke-width:2px,color:#000;
    classDef white fill:#ffffff,stroke:#000,color:#000;

    class A yellow
    class B blue
    class C green
    class D purple
    class E red
    class F lightblue
    class G white
    class H white
```
---

## ğŸ“Š KPIs Produced

| Metric | Description |
|--------|-------------|
| **orders** | Unique order count |
| **lines** | Items sold |
| **revenue** | price + freight (line-level revenue) |
| **customers** | Unique buyers |

Outputs are produced at two time grains:

- **Daily KPIs**
- **Monthly KPIs**

---

## âœ… Advertiser Fact Table

Includes:

- advertiser_id  
- order_id  
- customer_id  
- order_item_id  
- order_date  
- order_month  
- line_revenue  

This mirrors a **fact_sales** table used in enterprise analytics.

---

## âš™ï¸ How to Run the Pipeline

### 1. Create environment

```
conda create -n msad python=3.11 -y
conda activate msad
```

### 2. Install dependencies

```
pip install pandas pandera pyarrow python-dotenv pytest
```

### 3. Run ETL pipeline

```
python -m src.pipeline
```

### 4. Outputs appear in:

```
output/daily_advertiser_kpis.csv
output/monthly_advertiser_kpis.csv
```

---

## ğŸ§ª Data Validation (Pandera)

Validation ensures:

- Correct schema  
- Correct dtypes  
- No negative revenue  
- Valid advertiser/order/customer IDs  
- Correct YYYY-MM month format  
- Clean timestamps  

If validation fails, the pipeline stops â€” matching production design.

---

## ğŸ“œ Logging

Example logs:

```
INFO | Starting ETL pipeline...
INFO | Extract completed successfully.
INFO | Fact table validation passed.
INFO | KPI computation complete.
INFO | Load complete. Files saved to /output.
```

---

## ğŸ¯ Why This Project Matters

I demonstrate:

- ETL pipeline engineering  
- Fact table modeling  
- Data cleaning & standardization  
- KPI engineering  
- Validation & error handling  
- Logging & observability  
- Modular Python design  
- Reproducible environments  

Perfect for:

- Data Engineering  
- Analytics Engineering  
- Business Analytics  
- Data Analytics  

---

## ğŸ‘¤ Author

**Errol Brown**  
Data Engineering / Analytics
