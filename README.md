# ğŸ“Š Advertiser Analytics ETL Pipeline  
### End-to-End Data Engineering Project (Python, Pandas, Logging, Validation)

This project builds a **production-style ETL pipeline** that processes raw marketplace data (Olist dataset) and transforms it into **analytics-ready advertiser KPIs**.  
It is structured like a real engineering codebase used at Microsoft Advertising, Amazon Marketplace Analytics, and other retail media platforms.

---

## ğŸš€ Project Summary

This pipeline:

- Loads raw marketplace data (orders, items, customers, products)  
- Cleans & validates the datasets  
- Builds an advertiser-level **fact table**  
- Computes daily & monthly KPIs  
- Enforces data quality with **Pandera schema validation**  
- Logs every ETL stage  
- Outputs clean CSVs ready for BI dashboards or analytics  

The structure follows real DE standards with a modular **src/** package.

---

## ğŸ§± Tech Stack

- **Python 3.11**
- **Pandas**  
- **Pandera**  
- **Pathlib**  
- **Logging**  
- **Conda environment**  

---

## ğŸ“ Project Structure

```
ms_ad_analytics_project/
â”‚
â”œâ”€â”€ data/                           # Raw input CSVs (ignored by Git)
â”œâ”€â”€ output/                         # Final KPI outputs
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extract.py                  # Extract step
â”‚   â”œâ”€â”€ transform.py                # Clean, merge, build fact table
â”‚   â”œâ”€â”€ validate.py                 # Pandera schemas
â”‚   â”œâ”€â”€ load.py                     # Save outputs
â”‚   â”œâ”€â”€ logger.py                   # Custom logger
â”‚   â”œâ”€â”€ config.py                   # Config + log level
â”‚   â”œâ”€â”€ pipeline.py                 # Main ETL pipeline
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ advertiser_spend_analytics.ipynb
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ—ï¸ Pipeline Architecture (Mermaid Diagram)

```mermaid
flowchart TD

    A[Raw CSV Files<br/>orders, items, customers] --> B[Extract<br/>extract.py]
    B --> C[Clean & Normalize Data<br/>transform.py]
    C --> D[Build Advertiser Fact Table<br/>transform.py]
    D --> E[Validate with Pandera<br/>validate.py]
    E --> F[Compute KPIs<br/>daily + monthly]
    F --> G[Load Outputs<br/>load.py]
    G --> H[/output folder<br/>CSV exports]

    style A fill:#f8d568,stroke:#b8860b,stroke-width:2px,color:#000
    style B fill:#8ec5fc,stroke:#4682b4,stroke-width:2px,color:#000
    style C fill:#b5e8c8,stroke:#2e8b57,stroke-width:2px,color:#000
    style D fill:#f6d7fa,stroke:#8b3a9e,stroke-width:2px,color:#000
    style E fill:#ffe6e6,stroke:#cc0000,stroke-width:2px,color:#000
    style F fill:#e8e8ff,stroke:#6666cc,stroke-width:2px,color:#000
    style G fill:#ffffff,stroke:#000,color:#000
    style H fill:#ffffff,stroke:#000,color:#000
```

---

## ğŸ“Š KPIs Produced

Each advertiser receives:

| Metric | Description |
|--------|-------------|
| **orders** | Unique order count |
| **lines** | Items sold |
| **revenue** | price + freight (line-level revenue) |
| **customers** | Unique buyers |

Outputs delivered:

- **Daily KPIs**  
- **Monthly KPIs**  
- **Advertiser-level fact table**

---

## ğŸ“¦ Fact Table Schema (Advertiser-Level)

Key fields:

- `advertiser_id`  
- `order_id`  
- `customer_id`  
- `order_item_id`  
- `order_date`  
- `order_month`  
- `line_revenue`  

This mirrors a real **fact_sales** dataset used in enterprise analytics.

---

## âš™ï¸ How to Run the Pipeline

### 1ï¸âƒ£ Create & activate environment  
```
conda create -n msad python=3.11 -y
conda activate msad
```

### 2ï¸âƒ£ Install dependencies  
```
pip install pandas pandera pyarrow python-dotenv pytest
```

### 3ï¸âƒ£ Run the pipeline  
```
python -m src.pipeline
```

### 4ï¸âƒ£ Outputs will appear in `/output`  
```
output/daily_advertiser_kpis.csv
output/monthly_advertiser_kpis.csv
```

---

## ğŸ§ª Data Validation (Pandera)

The pipeline validates:

- Column presence  
- Data types  
- Non-negative revenue  
- Valid IDs  
- Date formatting (`YYYY-MM`)  
- No invalid timestamps  

Validation failures stop the pipeline â€” matching real production behavior.

---

## ğŸ“œ Logging (Production Workflow)

Example log:

```
INFO | Starting ETL pipeline...
INFO | Extract completed successfully.
INFO | Fact table validation passed.
INFO | KPI computation complete.
INFO | Load complete. Files saved to /output.
```

---

## ğŸ¯ Why This Project Matters

This project demonstrates real DE skills:

- ETL design  
- Fact table modeling  
- Data cleaning / normalization  
- KPI engineering  
- Pandera validation  
- Error handling  
- Logging & observability  
- Modular Python project architecture  
- Reproducible environments  

---

## ğŸŒ± Future Enhancements

- Incremental loading  
- Unit tests (pytest)  
- Use DuckDB or dbt for modeling  
- Schedule with Airflow or Prefect  
- Add a BI dashboard (Power BI / Tableau)  

---

## ğŸ‘¤ Author  
**Errol Brown**  
Data Engineering & Analytics  
